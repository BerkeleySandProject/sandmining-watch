{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ede6a-cec2-4306-b462-430933a476f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from project_config import GCP_PROJECT_NAME\n",
    "\n",
    "gcp_client = storage.Client(project=GCP_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.satmae.util import lr_decay as lrd\n",
    "from models.satmae.satmae_encoder_custom_decoder.satmae_encoder_linear_decoder import SatMaeSegmenterWithLinearDecoder\n",
    "\n",
    "model = SatMaeSegmenterWithLinearDecoder()\n",
    "param_groups = lrd.param_groups_lrd(model.encoder, 0.05,\n",
    "                                    no_weight_decay_list={'pos_embed', 'cls_token', 'dist_token'},\n",
    "                                    layer_decay=0.75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184df66e",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_configs.unet_fs_config import unet_fs_config\n",
    "from experiment_configs.satmae_ft_config import satmae_ft_doubleupsampling_config, satmae_ft_lineardecoder_config\n",
    "config = satmae_ft_doubleupsampling_config\n",
    "\n",
    "VALIDATION_SITES = [\"Ken_Banda\", \"Sone_Rohtas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b9bc0",
   "metadata": {},
   "source": [
    "### Create Rastervision datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda67a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from utils.rastervision_pipeline import observation_to_scene, scene_to_training_ds, scene_to_validation_ds, warn_if_nan_in_raw_raster\n",
    "from utils.data_management import observation_factory\n",
    "\n",
    "def is_validation(scene):\n",
    "    return any(\n",
    "        [validation_site in scene.id\n",
    "         for validation_site in VALIDATION_SITES]\n",
    "    )\n",
    "\n",
    "def is_training(scene):\n",
    "    return not is_validation(scene)\n",
    "\n",
    "\n",
    "all_observations = observation_factory(gcp_client)\n",
    "all_scenes = list(map(\n",
    "    lambda observation: observation_to_scene(config, observation),\n",
    "    all_observations\n",
    "))\n",
    "\n",
    "#for scene in all_scenes:\n",
    "#    warn_if_nan_in_raw_raster(scene.raster_source)\n",
    "\n",
    "training_scenes = list(filter(is_training, all_scenes))\n",
    "validation_scenes = list(filter(is_validation, all_scenes))\n",
    "\n",
    "training_datasets = list(map(\n",
    "    lambda scene: scene_to_training_ds(config, scene),\n",
    "    training_scenes\n",
    "))\n",
    "validation_datasets = list(map(\n",
    "    lambda scene: scene_to_validation_ds(config, scene),\n",
    "    validation_scenes\n",
    "))\n",
    "assert len(training_datasets) + len(validation_datasets) == len(all_scenes)\n",
    "\n",
    "train_dataset_merged = ConcatDataset(training_datasets)\n",
    "val_dataset_merged = ConcatDataset(validation_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6793687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizing import show_windows\n",
    "\n",
    "ds_to_visualize = training_datasets[11]\n",
    "ds_to_visualize = ds\n",
    "show_windows(\n",
    "    ds_to_visualize.scene.raster_source[:],\n",
    "    ds_to_visualize.windows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17bdfc-7fe5-49d4-a98d-79ad2a47f1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd23244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a94b65-7753-4ee8-abb9-7d62f3d272e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ml.rv_ml import construct_semantic_segmentation_learner\n",
    "from models.model_factory import model_factory\n",
    "\n",
    "_, _, n_channels = training_datasets[0].scene.raster_source.shape\n",
    "model = model_factory(\n",
    "    config,\n",
    "    n_channels=n_channels,\n",
    ")\n",
    "\n",
    "learner = construct_semantic_segmentation_learner(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    training_ds=training_datasets[0],  # for development and debugging, use training_datasets[0] or similar to speed up\n",
    "    validation_ds=training_datasets[1],  # for development and debugging, use training_datasets[1] or similar to speed up\n",
    ")\n",
    "learner.log_data_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f30020",
   "metadata": {},
   "source": [
    "## Check GPU Activity\n",
    "\n",
    "You can continuously monitor your GPU activity by using the command in the terminal\n",
    "\n",
    "\n",
    "`watch -d -n 0.5 nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad755047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want to log the run to W&B. You might need to authenticate to W&B.\n",
    "learner.initialize_wandb_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a710a-38ad-4d7b-9b4c-b19253b97dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.train(epochs=10)\n",
    "learner.save_model_bundle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6846be",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28120d3",
   "metadata": {},
   "source": [
    "Create SlidingWindowGeoDatasets for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.rastervision_pipeline import scene_to_prediction_ds\n",
    "\n",
    "# From the validation scenes, we construct new SlidingWindowGeoDatasets.\n",
    "# The difference between prediction_ds and validation_ds lies in the sliding window configuration,\n",
    "# the underlaying data is the same.\n",
    "\n",
    "prediction_ds = list(map(\n",
    "    lambda scene: scene_to_prediction_ds(config, scene),\n",
    "    validation_scenes\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233baf7",
   "metadata": {},
   "source": [
    "Run inference on prediction sites and log segmentation images to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807db479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from utils.wandb_utils import create_semantic_segmentation_image\n",
    "from ml.rv_ml import predict_class_for_site\n",
    "\n",
    "assert wandb.run is not None\n",
    "\n",
    "segmentation_result_images = []\n",
    "\n",
    "for idx, ds in enumerate(prediction_ds):\n",
    "    print(ds.scene.id)\n",
    "    rgb_img = ds.scene.raster_source.get_image_array()[:,:,1:4] # todo channels\n",
    "    predicted_mask = predict_class_for_site(learner, ds, crop_sz=0)\n",
    "    ground_truth_mask = ds.scene.label_source.get_label_arr()\n",
    "    segmantation_result_image = create_semantic_segmentation_image(\n",
    "        rgb_img, predicted_mask, ground_truth_mask, ds.scene.id\n",
    "    )\n",
    "    segmentation_result_images.append(segmantation_result_image)\n",
    "\n",
    "wandb.log({'Segmenation results': segmentation_result_images})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
