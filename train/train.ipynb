{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ede6a-cec2-4306-b462-430933a476f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa5fc2-678e-4e34-8666-95a964a3ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from project_config import GCP_PROJECT_NAME\n",
    "\n",
    "gcp_client = storage.Client(project=GCP_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184df66e",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "from experiment_configs.unet_fs_config import unet_orig_config, unet_resblocks_config, resnet18_unet_config\n",
    "from experiment_configs.satmae_ft_config import satmae_ft_doubleupsampling_config, satmae_ft_lineardecoder_config\n",
    "from experiment_configs.resnetmoco_ft_config import resnet50_moco_ft_config\n",
    "config = resnet50_moco_ft_config\n",
    "#config.output_dir = expanduser(\"~/sandmining-watch/out/1009_resnet50_moco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b9bc0",
   "metadata": {},
   "source": [
    "### Create Rastervision datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda67a90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from utils.rastervision_pipeline import observation_to_scene, scene_to_training_ds, scene_to_validation_ds, warn_if_nan_in_raw_raster\n",
    "from utils.data_management import observation_factory\n",
    "\n",
    "from project_config import is_training, is_validation\n",
    "\n",
    "\n",
    "all_observations = observation_factory(gcp_client)\n",
    "training_scenes = []\n",
    "validation_scenes = []\n",
    "\n",
    "for observation in all_observations:\n",
    "    is_train = is_training(observation.name)\n",
    "    is_val = is_validation(observation.name)\n",
    "\n",
    "    assert not (is_train and is_val), \"An observation cannot be in both training and validation\"\n",
    "\n",
    "    scene = observation_to_scene(config, observation)    \n",
    "    if is_train:\n",
    "        training_scenes.append(scene)\n",
    "    elif is_val:\n",
    "        validation_scenes.append(scene)\n",
    "    else:\n",
    "        print(f\"Ignoring observation {observation.name}\")\n",
    "\n",
    "\n",
    "#all_scenes = training_scenes + validation_scenes\n",
    "#for scene in all_scenes:\n",
    "#    warn_if_nan_in_raw_raster(scene.raster_source)\n",
    "\n",
    "training_datasets = [\n",
    "    scene_to_training_ds(config, scene) for scene in training_scenes\n",
    "]\n",
    "validation_datasets = [\n",
    "    scene_to_validation_ds(config, scene) for scene in validation_scenes\n",
    "]\n",
    "\n",
    "train_dataset_merged = ConcatDataset(training_datasets)\n",
    "val_dataset_merged = ConcatDataset(validation_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6793687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizing import Visualizer\n",
    "visualizer = Visualizer(config.s2_channels)\n",
    "\n",
    "train_ds = training_datasets[0]\n",
    "windows = [train_ds.sample_window() for _ in range(train_ds.max_windows)]\n",
    "visualizer.show_windows(\n",
    "    train_ds.scene.raster_source.get_image_array(),\n",
    "    windows\n",
    ")\n",
    "\n",
    "val_ds = validation_datasets[0]\n",
    "visualizer.show_windows(\n",
    "    val_ds.scene.raster_source.get_image_array(),\n",
    "    val_ds.windows\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17bdfc-7fe5-49d4-a98d-79ad2a47f1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd23244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a94b65-7753-4ee8-abb9-7d62f3d272e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.model_factory import model_factory\n",
    "from ml.optimizer_factory import optimizer_factory\n",
    "from ml.custom_learner import learner_factory\n",
    "\n",
    "_, _, n_channels = training_datasets[0].scene.raster_source.shape\n",
    "model = model_factory(\n",
    "    config,\n",
    "    n_channels=n_channels,\n",
    ")\n",
    "\n",
    "optimizer = optimizer_factory(config, model)\n",
    "\n",
    "learner = learner_factory(\n",
    "    config=config,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    training_ds=train_dataset_merged,  # for development and debugging, use training_datasets[0] or similar to speed up\n",
    "    validation_ds=val_dataset_merged,  # for development and debugging, use training_datasets[1] or similar to speed up\n",
    ")\n",
    "learner.log_data_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f30020",
   "metadata": {},
   "source": [
    "#### Check GPU Activity\n",
    "\n",
    "You can continuously monitor your GPU activity by using the command in the terminal\n",
    "\n",
    "\n",
    "`watch -d -n 0.5 nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad755047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want to log the run to W&B. You might need to authenticate to W&B.\n",
    "learner.initialize_wandb_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a710a-38ad-4d7b-9b4c-b19253b97dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.train(epochs=15)\n",
    "learner.save_model_bundle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6846be",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b78d1",
   "metadata": {},
   "source": [
    "Run inference on validation sites and log results to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.evaluate_and_log_to_wandb(validation_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rv_timm0412",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
