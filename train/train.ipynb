{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ede6a-cec2-4306-b462-430933a476f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from project_config import GCP_PROJECT_NAME\n",
    "\n",
    "gcp_client = storage.Client(project=GCP_PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184df66e",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b614ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_selection import ModelSelection\n",
    "import albumentations as A\n",
    "\n",
    "VALIDATION_SITES = [\"Ken_Banda\", \"Sone_Rohtas\"]\n",
    "TILE_SIZE = 110\n",
    "\n",
    "AUGMENTATION_TRAIN = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.CoarseDropout(max_height=32, max_width=32, max_holes=3)\n",
    "])\n",
    "\n",
    "EXPERIMENT_DIR = '../out/0831'\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "LR = 3e-2\n",
    "\n",
    "MODEL_TYPE = ModelSelection.Segformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b9bc0",
   "metadata": {},
   "source": [
    "### Create Rastervision datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda67a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from utils.rastervision_utils import observation_to_scene_s1s2, scene_to_training_ds, scene_to_validation_ds, warn_if_nan_in_raw_scene\n",
    "from utils.data_management import observation_factory\n",
    "\n",
    "def is_validation(scene):\n",
    "    return any(\n",
    "        [validation_site in scene.id\n",
    "         for validation_site in VALIDATION_SITES]\n",
    "    )\n",
    "\n",
    "def is_training(scene):\n",
    "    return not is_validation(scene)\n",
    "\n",
    "\n",
    "all_observations = observation_factory(gcp_client)\n",
    "all_scenes = list(map(\n",
    "    lambda observation: observation_to_scene_s1s2(observation),\n",
    "    all_observations\n",
    "))\n",
    "\n",
    "for scene in all_scenes:\n",
    "    warn_if_nan_in_raw_scene(scene)\n",
    "\n",
    "training_scenes = filter(is_training, all_scenes)\n",
    "validation_scenes = filter(is_validation, all_scenes)\n",
    "\n",
    "training_datasets = list(map(\n",
    "    lambda scene: scene_to_training_ds(scene, TILE_SIZE, AUGMENTATION_TRAIN),\n",
    "    training_scenes\n",
    "))\n",
    "validation_datasets = list(map(\n",
    "    lambda scene: scene_to_validation_ds(scene, TILE_SIZE),\n",
    "    validation_scenes\n",
    "))\n",
    "assert len(training_datasets) + len(validation_datasets) == len(all_scenes)\n",
    "\n",
    "train_dataset_merged = ConcatDataset(training_datasets)\n",
    "val_dataset_merged = ConcatDataset(validation_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ac684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizing import show_windows, show_image_in_dataset\n",
    "from project_config import DISPLAY_GROUPS, CLASS_CONFIG\n",
    "\n",
    "ds_to_visualize = training_datasets[2]\n",
    "show_windows(\n",
    "    ds_to_visualize.scene.raster_source[:,:],\n",
    "    ds_to_visualize.windows\n",
    ")\n",
    "show_image_in_dataset(\n",
    "    ds_to_visualize,\n",
    "    CLASS_CONFIG,\n",
    "    DISPLAY_GROUPS,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f17bdfc-7fe5-49d4-a98d-79ad2a47f1a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd23244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa446a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datasets[0].scene.raster_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a94b65-7753-4ee8-abb9-7d62f3d272e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rastervision_utils import construct_semantic_segmentation_learner\n",
    "from models.model_selection import get_model\n",
    "\n",
    "_, _, n_channels = training_datasets[0].scene.raster_source.shape\n",
    "model = get_model(\n",
    "    selection=MODEL_TYPE,\n",
    "    n_channels=n_channels,\n",
    "    img_size=(TILE_SIZE, TILE_SIZE),\n",
    ")\n",
    "\n",
    "learner = construct_semantic_segmentation_learner(\n",
    "    model=model,\n",
    "    training_ds=train_dataset_merged,  # for development and debugging, use training_datasets[0] or similar to speed up\n",
    "    validation_ds=val_dataset_merged,  # for development and debugging, use training_datasets[1] or similar to speed up\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    # class_loss_weights=[1., 10.],\n",
    "    experiment_dir=EXPERIMENT_DIR\n",
    ")\n",
    "learner.log_data_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f30020",
   "metadata": {},
   "source": [
    "## Check GPU Activity\n",
    "\n",
    "You can continuously monitor your GPU activity by using the command in the terminal\n",
    "\n",
    "\n",
    "`watch -d -n 0.5 nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "144a710a-38ad-4d7b-9b4c-b19253b97dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learner.train(epochs=1)\n",
    "learner.save_model_bundle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5b3a7",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "To activate tensorboard, run the following command in the terminal:\n",
    "`conda activate rastervision` (or whatever your conda environment is called)\n",
    "\n",
    "`tensorboard --logdir sandmining-watch/out` (make sure it's relative to your current path in the terminal)\n",
    "\n",
    "You will also need to port-forward; on your local machine, run:\n",
    "\n",
    "`ssh -N -f -L localhost:6006:localhost:6006 <USERNAME>@fati.ischool.berkeley.edu`\n",
    "\n",
    "Note: this is not needed if you're running from within VS Code- it should automatically give you the option to open tensorboard in the browser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raster_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
