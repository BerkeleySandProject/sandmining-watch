{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ab7001",
   "metadata": {},
   "source": [
    "# Observation Selector Notebook\n",
    "\n",
    "This notebook allows you to select regions of interest from a set of observations detailed in this [Google Spreadsheet](https://docs.google.com/spreadsheets/d/1Q1VfZWmh_BubeTz9Umjofx6Xz8bSb46xvrxBGNJupaE/edit#gid=0)\n",
    "\n",
    "\n",
    "In order to access the GCP bucket (only for those with credentials), you will need to follow [these instructions](https://cloud.google.com/iam/docs/keys-create-delete).\n",
    "Once you've done that, move the *.json file to `<home>/gcloud_keys/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f48fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import ipyleaflet\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import json\n",
    "    \n",
    "from ipyleaflet import WidgetControl\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "    \n",
    "project_id = 'gee-sand'\n",
    "home_dir = os.environ['HOME']\n",
    "\n",
    "##Currently only 1 file lives in this folder. \n",
    "### Individual users can also directly set the file name. \n",
    "cred_file_name = os.listdir(os.environ['HOME']+\"/gcloud_keys\")[0]\n",
    "\n",
    "with open(f\"{home_dir}/gcloud_keys/{cred_file_name}\") as source:\n",
    "    info = json.load(source)\n",
    "\n",
    "storage_credentials = service_account.Credentials.from_service_account_info(info)\n",
    "    \n",
    "storage_client = storage.Client(project=project_id, credentials=storage_credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d120cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=clGdK2OwOd1gfolgUXoArWNR_kbh0KCSJ5M4wT8oZ-g&tc=NLOqAFJ-suOQ09aKHYsmW1lrtWDan2Qes5E_1oHeo0A&cc=QA3miTeHfy4ky2NXIveuZ6ErudEJ5zvMKUDrWwF1wBg>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=clGdK2OwOd1gfolgUXoArWNR_kbh0KCSJ5M4wT8oZ-g&tc=NLOqAFJ-suOQ09aKHYsmW1lrtWDan2Qes5E_1oHeo0A&cc=QA3miTeHfy4ky2NXIveuZ6ErudEJ5zvMKUDrWwF1wBg</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        ee.Initialize()\n",
    "except Exception as e:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9346f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define Globals\n",
    "start_year = 2022\n",
    "end_year = 2022\n",
    "start_month = 1\n",
    "end_month = 12\n",
    "\n",
    "s1_bands = ['VV', 'VH']\n",
    "s2_bands_rgb = ['B4', 'B3' , 'B2']\n",
    "s2_bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']\n",
    "\n",
    "display_buffer = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded3e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gcs_list_folders(bucket, prefix=\"\", delimeter=\"/\", guess_lexicographically_last_item=\"~\", gcs_client=None):\n",
    "    \"\"\"\n",
    "    Function to read folders from GCS buckets\n",
    "    \"\"\"\n",
    "    folders = set()\n",
    "    prefix_parts = prefix.split(delimeter)\n",
    "    start_offset = \"/\".join(prefix_parts)\n",
    "    last_blob_name = None\n",
    "    while True:\n",
    "        blobs = list(gcs_client.list_blobs(\n",
    "            bucket_or_name=bucket,\n",
    "            prefix=prefix,\n",
    "            start_offset=start_offset,\n",
    "            max_results=1\n",
    "        ))\n",
    "        if not blobs:\n",
    "            break\n",
    "        blob = blobs[0]\n",
    "        if last_blob_name == blob.name:\n",
    "            raise Exception(\"Saw blob {} twice, try setting a different guess_lexicographically_last_item={}.\".format(\n",
    "                repr(blob.name), repr(guess_lexicographically_last_item)\n",
    "            ))\n",
    "        folder = delimeter.join(blob.name.split(delimeter)[0:len(prefix_parts)] + [\"\"])\n",
    "        folders.add(folder)\n",
    "        start_offset = folder + guess_lexicographically_last_item\n",
    "        last_blob_name = blob.name\n",
    "        try_characters = 1\n",
    "\n",
    "    return folders\n",
    "\n",
    "def toDb(image):\n",
    "    \"\"\"\n",
    "    Converts S1 image to decibel scale\n",
    "    \"\"\"\n",
    "    return image.addBands(\n",
    "    ee.Image().expression('10 * log10(linear)', {\n",
    "      'linear': image.select(['VV', 'VH'])\n",
    "      }),None, True); # Replace the bands to keep image properties\n",
    "\n",
    "def dbNorm(image):\n",
    "    \"\"\"\n",
    "    Normalizes an S1 image\n",
    "    \"\"\"\n",
    "    return ee.Image(image.divide(30.0).add(1.0))\n",
    "\n",
    "def getCover(image, aoi, scale):\n",
    "\n",
    "    # calculate the number of inputs\n",
    "    totPixels = ee.Number(image.unmask(1).reduceRegion(**{\n",
    "      'reducer': ee.Reducer.count(),\n",
    "      'scale': scale,\n",
    "      'geometry': aoi,\n",
    "    }).values().get(0))\n",
    "\n",
    "    # Calculate the actual amount of pixels inside the aoi\n",
    "    actPixels = ee.Number(image.reduceRegion(**{\n",
    "      'reducer': ee.Reducer.count(),\n",
    "      'scale': scale,\n",
    "      'geometry': aoi,\n",
    "    }).values().get(0))\n",
    "\n",
    "    # calculate the perc of cover\n",
    "    percCover = actPixels.divide(totPixels).multiply(100).round()\n",
    "    percCover = percCover.getInfo()\n",
    "    return percCover\n",
    "\n",
    "def get_s1_median(year, month, aoi, clip = True):\n",
    "    \"\"\"\n",
    "    Get median composite S1 image (in dB), for a given area, year and month. \n",
    "    \n",
    "    \"\"\"\n",
    "    img = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT')\\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\\n",
    "        .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "        .filterBounds(aoi)\\\n",
    "        .filter(ee.Filter.calendarRange(int(year), int(year), 'year'))\\\n",
    "        .filter(ee.Filter.calendarRange(int(month), int(month), 'month'))\\\n",
    "        .median()\n",
    "    \n",
    "    if clip:\n",
    "        img = img.clip(aoi)\n",
    "    \n",
    "    img = toDb(img)\n",
    "\n",
    "    img = img.set({'month': ee.Date.fromYMD(int(year), int(month), 1)})\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_s2_median(year, month, aoi, clip = True):\n",
    "    \"\"\"\n",
    "    Get median composite S2, for a given area, year and month. \n",
    "    \"\"\"\n",
    "    img = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "        .filterBounds(ee.FeatureCollection(aoi).geometry().centroid().buffer(display_buffer))\\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\\\n",
    "        .filter(ee.Filter.calendarRange(int(year), int(year), 'year'))\\\n",
    "        .filter(ee.Filter.calendarRange(int(month), int(month), 'month'))\\\n",
    "        .median()\n",
    "        \n",
    "    img = img.set({'month': ee.Date.fromYMD(int(year), int(month), 1)})\n",
    "    if clip:\n",
    "        img = img.clip(aoi)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_progress_bar(task_dict):\n",
    "    \"\"\"\n",
    "    Returns progress bar. Takes a couple of seconds each time. \n",
    "    \"\"\"\n",
    "    n_tasks = len(task_dict)\n",
    "    for rec in tqdm([1 for t in task_dict.values() if t.status()['state'] == 'COMPLETED'], \n",
    "                             total=n_tasks, \n",
    "                             desc=\"Progress\"):\n",
    "        # any code prcessing the elements in the iterable\n",
    "        pass\n",
    "    \n",
    "\n",
    "def remove_layers(layer_list):\n",
    "    \"\"\"\n",
    "    Given a list of map layers, remove it.\n",
    "    \"\"\"\n",
    "    for l in layer_list:\n",
    "        Map.remove_ee_layer(l)\n",
    "        \n",
    "def get_new_feats(new_aoi_name):\n",
    "    \"\"\"\n",
    "    Given an AOI, get the point location, river name, and district name\n",
    "    \"\"\"\n",
    "    temp2 = label_candidates[label_candidates['Name'] == new_aoi_name]\n",
    "    new_pt = ee.Geometry.Point(list(temp2[['longitude', 'latitude']].values[0]))\n",
    "    river = temp2['River'].values[0]\n",
    "    district = temp2['District'].values[0]\n",
    "    \n",
    "    return new_pt, river, district\n",
    "\n",
    "layer_map = None\n",
    "all_tasks = {}\n",
    "\n",
    "def get_tasks(aoi1):\n",
    "    \"\"\"\n",
    "    Create all export tasks. \n",
    "    \"\"\"       \n",
    "    cent =  aoi1.centroid().geometry().coordinates()\n",
    "    \n",
    "    ### For th\n",
    "    check_names = ['Betwa RIver, Hamirpur',\n",
    "                   'Ken river, Banda district', \n",
    "                   'Kathajodi River, Cuttack',\n",
    "                   'Narmada River, Sehore, MP', \n",
    "                   'Chambal 2', \n",
    "                   'Sone, Dehri',\n",
    "                   'Tawa river, Hoshangabad, MP']\n",
    "    #For these aois, the lat lon values in the location key are based\n",
    "    #on the lat lon values provided in the Google Spreadsheet, and not on the centroid of the AOI. \n",
    "    \n",
    "    if curr_aoi_name in check_names:\n",
    "        lon = label_candidates[label_candidates['Name'] == curr_aoi_name]['longitude'].values[0]\n",
    "        lat = label_candidates[label_candidates['Name'] == curr_aoi_name]['latitude'].values[0]\n",
    "    else:\n",
    "        lon = cent.get(0).getInfo()\n",
    "        lat = cent.get(1).getInfo()\n",
    "    river_name = river\n",
    "    district_name = district\n",
    "    \n",
    "    start_val = date1.value\n",
    "    end_val = date2.value\n",
    "    \n",
    "    start_year = start_val.year\n",
    "    end_year = end_val.year\n",
    "    \n",
    "    start_month = start_val.month\n",
    "    end_month = end_val.month\n",
    "    \n",
    "    stub = f\"{river_name}_{district_name}_{str(np.round(lon, 2)).replace('.', '-')}_{str(np.round(lat, 2)).replace('.', '-')}\"\n",
    "\n",
    "    task_dict = {}\n",
    "    for dt in pd.date_range(start = f\"{start_year}-{start_month}-01\", end = f\"{end_year}-{end_month}-01\", freq = 'MS'):\n",
    "        year = int(dt.year)\n",
    "        month = int(dt.month)\n",
    "        if month <10:\n",
    "            mstub = '0'+str(month)\n",
    "        else:\n",
    "            mstub = str(month)\n",
    "\n",
    "\n",
    "        s1_img = get_s1_median(year, month, aoi1.geometry())\n",
    "        s2_img = get_s2_median(year, month, aoi1.geometry())\n",
    "\n",
    "        ### Added logic to export images iff both s1 and s2 images have data. \n",
    "        try:\n",
    "            ##Easiest way to check -- if VV and VH bands are not available, the line below will trigger an error. \n",
    "            l1 = s1_img.bandNames().length().getInfo()\n",
    "        except:\n",
    "            l1 = 0\n",
    "\n",
    "        try:\n",
    "            l2 = s2_img.bandNames().length().getInfo()\n",
    "        except:\n",
    "            l2 = 0\n",
    "\n",
    "        if (l1 >0) & (l2 >0):\n",
    "            \n",
    "            percCover_s1 = getCover(s1_img, aoi1.geometry(), 100)\n",
    "            percCover_s2 = getCover(s2_img, aoi1.geometry(), 100)\n",
    "            \n",
    "            if (percCover_s1 == 100) & (percCover_s2 == 100):\n",
    "\n",
    "                task_s1 = ee.batch.Export.image.toCloudStorage(\n",
    "                                        image = s1_img.select(s1_bands),\n",
    "                                        description = stub + \"_\" + str(year) + \"_\" + mstub + '_s1',\n",
    "                                        bucket = 'sand_mining_median',\n",
    "                                        fileNamePrefix=  'labels/' + stub + \"_median/s1/\"+stub + \"_\" + str(year) + \"-\" + mstub + \"-01\"  + \"_s1\",\n",
    "                                        region = aoi1.geometry(),\n",
    "                                        scale = 10,\n",
    "                                        crs = 'EPSG:4326', \n",
    "                                        maxPixels = 1e13\n",
    "                                        )\n",
    "                task_s2_rgb = ee.batch.Export.image.toCloudStorage(\n",
    "                                        image = s2_img.select(s2_bands_rgb).visualize(**{\"bands\":['B4', 'B3', 'B2'], \n",
    "                                                                                       \"min\":0, \n",
    "                                                                                       \"max\":3500}),\n",
    "                                        description = stub + \"_\" + str(year) + \"_\" + mstub + '_rgb',\n",
    "                                        bucket = 'sand_mining_median',\n",
    "                                        fileNamePrefix=  'labels/' + stub + \"_median/rgb/\"+stub + \"_\" + str(year) + \"-\" + mstub + \"-01\" + \"_rgb\",\n",
    "                                        region = aoi1.geometry(),\n",
    "                                        scale = 10,\n",
    "                                        crs = 'EPSG:4326', \n",
    "                                        maxPixels = 1e13\n",
    "                                        )\n",
    "\n",
    "                task_s2_bs = ee.batch.Export.image.toCloudStorage(\n",
    "                                image = s2_img.select(s2_bands),\n",
    "                                description = stub + \"_\" + str(year) + \"_\" + str(month) + '_s2',\n",
    "                                bucket = 'sand_mining_median',\n",
    "                                fileNamePrefix=  'labels/' + stub + \"_median/s2/\" + stub + \"_\" + str(year) + \"-\" + mstub + \"-01\" + \"_s2\",\n",
    "                                region = aoi1.geometry(),\n",
    "                                scale = 10,\n",
    "                                crs = 'EPSG:4326', \n",
    "                                maxPixels = 1e13\n",
    "                                )\n",
    "                task_s1.start()\n",
    "                task_dict[f'{stub}_{year}_{month}_s1'] = task_s1\n",
    "                task_s2_rgb.start()\n",
    "                task_dict[f'{stub}_{year}_{month}_s2_rgb'] = task_s2_rgb\n",
    "                task_s2_bs.start()\n",
    "                task_dict[f'{stub}_{year}_{month}_s2_bs'] = task_s2_bs\n",
    "            else:\n",
    "                logging.info(f\"{stub}_{year}_{month} not Exported!\")\n",
    "                logging.info(f\"\"\"S2 has {percCover_s2}% Coverage, and S1 has {percCover_s1}% Coverage.\"\"\")\n",
    "\n",
    "        else:\n",
    "            logging.info(f\"{stub}_{year}_{month} not Exported!\")\n",
    "            logging.info(f\"\"\"S2 has {l1} bands, and S1 has {l2} bands.\"\"\")\n",
    "\n",
    "    \n",
    "    if aoi_is_new:\n",
    "        logging.info(\"AOI does not exist -- exporting to GC Bucket\")\n",
    "        task_shp = ee.batch.Export.table.toCloudStorage(\n",
    "                          collection = ee.FeatureCollection(aoi1),\n",
    "                          description = stub,\n",
    "                          bucket = 'sand_mining_median',\n",
    "                          fileNamePrefix = 'labels/' + stub+'_median/shp/'+stub,\n",
    "                          fileFormat = 'GeoJSON')\n",
    "\n",
    "        task_shp.start()\n",
    "        task_dict[f'{stub}_shp'] = task_shp\n",
    "            \n",
    "    return task_dict\n",
    "\n",
    "\n",
    "def on_dropdown_change(change):\n",
    "    \"\"\"\n",
    "    Event handler for the dropdown:\n",
    "    each time a selection is made, moves the map to the new selection, updates globals, \n",
    "    and removes old layers. \n",
    "    \"\"\"\n",
    "    global old_names\n",
    "    global old_river_name\n",
    "    global old_district_name\n",
    "    global river\n",
    "    global district\n",
    "    global layer_map\n",
    "    global curr_aoi_name\n",
    "    global curr_aoi\n",
    "    \n",
    "    clear_button.disabled = True\n",
    "    button.disabled = True\n",
    "    date1.value = None\n",
    "    date2.value = None\n",
    "    \n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        new_aoi_name = change['new']\n",
    "        old_aoi_name = change['old']\n",
    "    \n",
    "        curr_aoi_name = new_aoi_name\n",
    "        \n",
    "        new_pt, river, district = get_new_feats(new_aoi_name)\n",
    "        curr_aoi = new_pt\n",
    "        \n",
    "        if old_aoi_name is not None:\n",
    "            Map.remove_ee_layer(old_aoi_name)\n",
    "            \n",
    "        if old_river_name:\n",
    "            layers = list(Map.layers)\n",
    "            remove_list = [l.name for l in layers if (old_river_name in l.name) & (old_district_name in l.name) ]\n",
    "            if len(remove_list) > 0 :\n",
    "                remove_layers(remove_list)\n",
    "                \n",
    "        Map.remove_last_drawn()\n",
    "            \n",
    "        Map.addLayer(new_pt, {}, new_aoi_name)\n",
    "        Map.centerObject(new_pt, zoom = 10)\n",
    "        \n",
    "        folderlist = gcs_list_folders(bucket=\"sand_mining_median\", \n",
    "                                      prefix = f'labels/{river}_{district}',\n",
    "                                      gcs_client=storage_client)\n",
    "        \n",
    "        layer_map = {}\n",
    "        \n",
    "        for f in folderlist:\n",
    "            fname = f.split(\"/\")[1].replace(\"_median\", \"\")\n",
    "            try:\n",
    "                tmp1 = gpd.read_file(f\"https://storage.googleapis.com/sand_mining_median/{f}shp/{fname}.geojson\")\n",
    "                featureCollection = ee.FeatureCollection(json.loads(tmp1.to_json()))\n",
    "                layer_map[fname] = featureCollection\n",
    "                Map.addLayer(featureCollection, {}, fname)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        old_river_name = river\n",
    "        old_district_name = district\n",
    "\n",
    "\n",
    "def get_final_aoi():\n",
    "    \"\"\"\n",
    "    Returns either the last AOI layer, or the last drawn layer. \n",
    "    If neither is available, returns error. \n",
    "    \"\"\"\n",
    "    global aoi_is_new\n",
    "    keep = [\n",
    "        l.name for l in Map.layers if (l.visible) & \n",
    "                                      (river in l.name) & \n",
    "                                      (district in l.name) & \n",
    "                                      (curr_aoi_name != l.name)\n",
    "       ]\n",
    "    \n",
    "    if len(keep) > 0:\n",
    "        old_aoi = layer_map[keep[0]].first()\n",
    "    else:\n",
    "        old_aoi = None\n",
    "        \n",
    "    new_aoi = Map.draw_last_feature\n",
    "    \n",
    "    if new_aoi is not None:\n",
    "        final_aoi = new_aoi\n",
    "        aoi_is_new = True\n",
    "    elif (new_aoi is None) & (old_aoi is not None):\n",
    "        final_aoi = old_aoi\n",
    "        aoi_is_new = False\n",
    "    else:\n",
    "        print(\"Select an AOI!\")\n",
    "        aoi_is_new = False\n",
    "        \n",
    "    return ee.Feature(final_aoi)\n",
    "        \n",
    "def callback1(b):\n",
    "    \"\"\"\n",
    "    Event handler for the export button:\n",
    "    On click, creates and kicks off all tasks\n",
    "    \"\"\"\n",
    "    global all_tasks\n",
    "    print(\"Exporting to GC Bucket, please wait...\")\n",
    "    last_feature = get_final_aoi()\n",
    "    last_feature_type = last_feature.geometry().type().getInfo()\n",
    "    assert last_feature_type == 'Polygon', 'Pick/Draw a Polygon!'\n",
    "    new_tasks = get_tasks(last_feature)\n",
    "    all_tasks.update(new_tasks)\n",
    "    \n",
    "    \n",
    "# Handle click event\n",
    "def on_button_clicked(b):\n",
    "    \"\"\"\n",
    "    Event handler for the clear drawing button\n",
    "    \"\"\"\n",
    "    dc.clear()\n",
    "    Map.remove_last_drawn()\n",
    "    \n",
    "def handle_draw(self, action, geo_json):\n",
    "    \"\"\"\n",
    "    handler to disable the clear button, upon adding a drawing\n",
    "    \"\"\"\n",
    "    clear_button.disabled = False\n",
    "\n",
    "def on_start_date_change(change):\n",
    "    \"\"\"\n",
    "    handler to deal with new start date\n",
    "    \"\"\"\n",
    "    \n",
    "    if change['type'] == 'change' and change['name'] == 'value' and change['new'] is not None: \n",
    "        #This should happen only upon a real date selection, \n",
    "        #Not when the date picker gets reset. \n",
    "        new_year = change['new'].year\n",
    "        new_month = change['new'].month\n",
    "\n",
    "        if change['old'] is not None:\n",
    "            old_year = change['old'].year\n",
    "            old_month = change['old'].month\n",
    "            old_layer_name = f\"Start: S2 - Median {old_year} - {old_month}\"\n",
    "            Map.remove_ee_layer(old_layer_name)\n",
    "\n",
    "        new_img = get_s2_median(new_year, new_month, curr_aoi, clip = False)\n",
    "        Map.addLayer(new_img,  {\"bands\":['B4', 'B3', 'B2'], 'min':0, 'max':3500}, f\"Start: S2 - Median {new_year} - {new_month}\" )\n",
    "        button.disabled = True\n",
    "    else:\n",
    "        layer_names = [l.name for l in Map.layers if 'Start: S2 - Median' in l.name]\n",
    "        for l in layer_names:\n",
    "            Map.remove_ee_layer(l)\n",
    "            \n",
    "        \n",
    "    \n",
    "def on_end_date_change(change):\n",
    "    \"\"\"\n",
    "    handler to deal with new end date. \n",
    "    \"\"\"\n",
    "    if change['type'] == 'change' and change['name'] == 'value' and change['new'] is not None:\n",
    "        #This should happen only upon a real date selection, \n",
    "        #Not when the date picker gets reset. \n",
    "        new_year = change['new'].year\n",
    "        new_month = change['new'].month\n",
    "\n",
    "        if change['old'] is not None:\n",
    "            old_year = change['old'].year\n",
    "            old_month = change['old'].month\n",
    "            old_layer_name = f\"End: S2 - Median {old_year} - {old_month}\"\n",
    "            Map.remove_ee_layer(old_layer_name)\n",
    "\n",
    "        new_img = get_s2_median(new_year, new_month, curr_aoi, clip = False)\n",
    "        Map.addLayer(new_img,  {\"bands\":['B4', 'B3', 'B2'], 'min':0, 'max':3500}, f\"End: S2 - Median {new_year} - {new_month}\" )\n",
    "\n",
    "        button.disabled = False\n",
    "    else:\n",
    "        layer_names = [l.name for l in Map.layers if 'End: S2 - Median' in l.name]\n",
    "        for l in layer_names:\n",
    "            Map.remove_ee_layer(l)\n",
    "            \n",
    "\n",
    "# from google.cloud.storage.client import Client\n",
    "\n",
    "# gcs_client = Client()\n",
    "\n",
    "# print(gcs_list_folders(bucket=\"sand_mining_median\", gcs_client=gcs_client))\n",
    "# print(gcs_list_folders(bucket=\"my-bucket\", prefix=\"foo/\", gcs_client=gcs_client))\n",
    "# print(gcs_list_folders(bucket=\"my-bucket\", prefix=\"foo/bar/\", gcs_client=gcs_client))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7a77e",
   "metadata": {},
   "source": [
    "## Get observations from Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d8f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = \"1Q1VfZWmh_BubeTz9Umjofx6Xz8bSb46xvrxBGNJupaE\"\n",
    "sheet_name = \"Sheet1\"\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        \n",
    "label_candidates = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c628913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4104357d4f8a4d4d8808ebf0e2eb21e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[25, 82], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resetting logger (important for Jupyter)\n",
    "logger = logging.getLogger()\n",
    "for handler in logger.handlers[:]:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# Configure logging settings\n",
    "logging.basicConfig(filename=f'{str(datetime.now().replace(second=0, microsecond = 0)).replace(\" \", \"_\")}.log',  # the file where logs will be saved\n",
    "                    level=logging.INFO,  # level of logging to capture (DEBUG captures all levels)\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')  # format for each log entry\n",
    "\n",
    "\n",
    "folders = gcs_list_folders(bucket=\"sand_mining_median\", prefix = 'labels/' , gcs_client=storage_client)\n",
    "\n",
    "old_names = None\n",
    "old_river_name = None\n",
    "old_district_name = None\n",
    "curr_aoi_name = None\n",
    "\n",
    "river, district = None, None\n",
    "aoi_is_new = False\n",
    "curr_aoi = None\n",
    "        \n",
    "names1  = label_candidates.Name.values\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=names1, value=None, description='Label candidates'\n",
    ")\n",
    "dropdown.observe(on_dropdown_change)\n",
    "dropdown_ctrl = WidgetControl(widget=dropdown, position='topright')\n",
    "\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Export Medians',\n",
    "    button_style='info',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check',  # (FontAwesome names without the `fa-` prefix)\n",
    "    disabled = True\n",
    ")\n",
    "button.on_click(callback1)\n",
    "\n",
    "date1 = widgets.DatePicker(\n",
    "    description='Pick Start Date',\n",
    "    disabled=False\n",
    ")\n",
    "date1.observe(on_start_date_change, names='value')\n",
    "\n",
    "date2 = widgets.DatePicker(\n",
    "    description='Pick End Date',\n",
    "    disabled=False\n",
    ")\n",
    "date2.observe(on_end_date_change, names='value')\n",
    "\n",
    "clear_button = widgets.Button(description=\"Clear drawings\", disabled = True)\n",
    "clear_button.on_click(on_button_clicked)\n",
    "\n",
    "btn_control = WidgetControl(widget=clear_button, position='topright')\n",
    "\n",
    "\n",
    "Map = geemap.Map(center = (25, 82), zoom = 10)\n",
    "Map.add_basemap('SATELLITE')\n",
    "\n",
    "\n",
    "dc = Map.draw_control  \n",
    "dc.on_draw(handle_draw)\n",
    "\n",
    "\n",
    "s2_median = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\\\n",
    "        .filter(ee.Filter.calendarRange(start_year, end_year, 'year'))\\\n",
    "        .filter(ee.Filter.calendarRange(int(start_month), int(end_month), 'month'))\\\n",
    "        .median()\n",
    "\n",
    "Map.addLayer(s2_median, {\"bands\":['B4', 'B3', 'B2'], 'min':0, 'max':3500}, 'S2 Median')\n",
    "\n",
    "Map.add_control(dropdown_ctrl)\n",
    "Map.add_control(btn_control)\n",
    "\n",
    "Map.add_widget(button, position = \"bottomright\")\n",
    "Map.add_widget(date2, position = \"bottomright\")\n",
    "Map.add_widget(date1, position = \"bottomright\")\n",
    "# # Get the DrawControl\n",
    "# dc = Map.draw_control\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d57c41",
   "metadata": {},
   "source": [
    "## Check progress status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ab0410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8198ba67694e60b283daa4bd650368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Monitor Progress\n",
    "get_progress_bar(all_tasks)\n",
    "\n",
    "for key in all_tasks.keys():\n",
    "    print(key, all_tasks[key].status()['state'])\n",
    "    # display error messages per failed task\n",
    "    if all_tasks[key].status()['state'] == 'FAILED':\n",
    "        print(all_tasks[key].status()['error_message'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
