{"format": "torch", "nodes": [{"name": "encoder", "id": 139741948526304, "class_name": "GroupChannelsVisionTransformer(\n  (patch_embed): ModuleList(\n    (0-1): 2 x PatchEmbed(\n      (proj): Conv2d(4, 1024, kernel_size=(8, 8), stride=(8, 8))\n      (norm): Identity()\n    )\n    (2): PatchEmbed(\n      (proj): Conv2d(2, 1024, kernel_size=(8, 8), stride=(8, 8))\n      (norm): Identity()\n    )\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): Identity()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (1): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (2): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (3): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (4): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (5): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (6): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (7): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (8): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (9): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (10): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (11): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (12): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (13): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (14): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (15): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (16): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (17): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (18): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (19): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (20): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (21): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (22): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n    (23): Block(\n      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (drop_path): DropPath()\n      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n        (act): GELU(approximate='none')\n        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n        (drop): Dropout(p=0.0, inplace=False)\n      )\n    )\n  )\n  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n  (pre_logits): Identity()\n  (head): Linear(in_features=1024, out_features=2, bias=True)\n)", "parameters": [["cls_token", [1, 1, 1024]], ["pos_embed", [1, 401, 768]], ["channel_embed", [1, 3, 256]], ["channel_cls_embed", [1, 1, 256]], ["patch_embed.0.proj.weight", [1024, 4, 8, 8]], ["patch_embed.0.proj.bias", [1024]], ["patch_embed.1.proj.weight", [1024, 4, 8, 8]], ["patch_embed.1.proj.bias", [1024]], ["patch_embed.2.proj.weight", [1024, 2, 8, 8]], ["patch_embed.2.proj.bias", [1024]], ["blocks.0.norm1.weight", [1024]], ["blocks.0.norm1.bias", [1024]], ["blocks.0.attn.qkv.weight", [3072, 1024]], ["blocks.0.attn.qkv.bias", [3072]], ["blocks.0.attn.proj.weight", [1024, 1024]], ["blocks.0.attn.proj.bias", [1024]], ["blocks.0.norm2.weight", [1024]], ["blocks.0.norm2.bias", [1024]], ["blocks.0.mlp.fc1.weight", [4096, 1024]], ["blocks.0.mlp.fc1.bias", [4096]], ["blocks.0.mlp.fc2.weight", [1024, 4096]], ["blocks.0.mlp.fc2.bias", [1024]], ["blocks.1.norm1.weight", [1024]], ["blocks.1.norm1.bias", [1024]], ["blocks.1.attn.qkv.weight", [3072, 1024]], ["blocks.1.attn.qkv.bias", [3072]], ["blocks.1.attn.proj.weight", [1024, 1024]], ["blocks.1.attn.proj.bias", [1024]], ["blocks.1.norm2.weight", [1024]], ["blocks.1.norm2.bias", [1024]], ["blocks.1.mlp.fc1.weight", [4096, 1024]], ["blocks.1.mlp.fc1.bias", [4096]], ["blocks.1.mlp.fc2.weight", [1024, 4096]], ["blocks.1.mlp.fc2.bias", [1024]], ["blocks.2.norm1.weight", [1024]], ["blocks.2.norm1.bias", [1024]], ["blocks.2.attn.qkv.weight", [3072, 1024]], ["blocks.2.attn.qkv.bias", [3072]], ["blocks.2.attn.proj.weight", [1024, 1024]], ["blocks.2.attn.proj.bias", [1024]], ["blocks.2.norm2.weight", [1024]], ["blocks.2.norm2.bias", [1024]], ["blocks.2.mlp.fc1.weight", [4096, 1024]], ["blocks.2.mlp.fc1.bias", [4096]], ["blocks.2.mlp.fc2.weight", [1024, 4096]], ["blocks.2.mlp.fc2.bias", [1024]], ["blocks.3.norm1.weight", [1024]], ["blocks.3.norm1.bias", [1024]], ["blocks.3.attn.qkv.weight", [3072, 1024]], ["blocks.3.attn.qkv.bias", [3072]], ["blocks.3.attn.proj.weight", [1024, 1024]], ["blocks.3.attn.proj.bias", [1024]], ["blocks.3.norm2.weight", [1024]], ["blocks.3.norm2.bias", [1024]], ["blocks.3.mlp.fc1.weight", [4096, 1024]], ["blocks.3.mlp.fc1.bias", [4096]], ["blocks.3.mlp.fc2.weight", [1024, 4096]], ["blocks.3.mlp.fc2.bias", [1024]], ["blocks.4.norm1.weight", [1024]], ["blocks.4.norm1.bias", [1024]], ["blocks.4.attn.qkv.weight", [3072, 1024]], ["blocks.4.attn.qkv.bias", [3072]], ["blocks.4.attn.proj.weight", [1024, 1024]], ["blocks.4.attn.proj.bias", [1024]], ["blocks.4.norm2.weight", [1024]], ["blocks.4.norm2.bias", [1024]], ["blocks.4.mlp.fc1.weight", [4096, 1024]], ["blocks.4.mlp.fc1.bias", [4096]], ["blocks.4.mlp.fc2.weight", [1024, 4096]], ["blocks.4.mlp.fc2.bias", [1024]], ["blocks.5.norm1.weight", [1024]], ["blocks.5.norm1.bias", [1024]], ["blocks.5.attn.qkv.weight", [3072, 1024]], ["blocks.5.attn.qkv.bias", [3072]], ["blocks.5.attn.proj.weight", [1024, 1024]], ["blocks.5.attn.proj.bias", [1024]], ["blocks.5.norm2.weight", [1024]], ["blocks.5.norm2.bias", [1024]], ["blocks.5.mlp.fc1.weight", [4096, 1024]], ["blocks.5.mlp.fc1.bias", [4096]], ["blocks.5.mlp.fc2.weight", [1024, 4096]], ["blocks.5.mlp.fc2.bias", [1024]], ["blocks.6.norm1.weight", [1024]], ["blocks.6.norm1.bias", [1024]], ["blocks.6.attn.qkv.weight", [3072, 1024]], ["blocks.6.attn.qkv.bias", [3072]], ["blocks.6.attn.proj.weight", [1024, 1024]], ["blocks.6.attn.proj.bias", [1024]], ["blocks.6.norm2.weight", [1024]], ["blocks.6.norm2.bias", [1024]], ["blocks.6.mlp.fc1.weight", [4096, 1024]], ["blocks.6.mlp.fc1.bias", [4096]], ["blocks.6.mlp.fc2.weight", [1024, 4096]], ["blocks.6.mlp.fc2.bias", [1024]], ["blocks.7.norm1.weight", [1024]], ["blocks.7.norm1.bias", [1024]], ["blocks.7.attn.qkv.weight", [3072, 1024]], ["blocks.7.attn.qkv.bias", [3072]], ["blocks.7.attn.proj.weight", [1024, 1024]], ["blocks.7.attn.proj.bias", [1024]], ["blocks.7.norm2.weight", [1024]], ["blocks.7.norm2.bias", [1024]], ["blocks.7.mlp.fc1.weight", [4096, 1024]], ["blocks.7.mlp.fc1.bias", [4096]], ["blocks.7.mlp.fc2.weight", [1024, 4096]], ["blocks.7.mlp.fc2.bias", [1024]], ["blocks.8.norm1.weight", [1024]], ["blocks.8.norm1.bias", [1024]], ["blocks.8.attn.qkv.weight", [3072, 1024]], ["blocks.8.attn.qkv.bias", [3072]], ["blocks.8.attn.proj.weight", [1024, 1024]], ["blocks.8.attn.proj.bias", [1024]], ["blocks.8.norm2.weight", [1024]], ["blocks.8.norm2.bias", [1024]], ["blocks.8.mlp.fc1.weight", [4096, 1024]], ["blocks.8.mlp.fc1.bias", [4096]], ["blocks.8.mlp.fc2.weight", [1024, 4096]], ["blocks.8.mlp.fc2.bias", [1024]], ["blocks.9.norm1.weight", [1024]], ["blocks.9.norm1.bias", [1024]], ["blocks.9.attn.qkv.weight", [3072, 1024]], ["blocks.9.attn.qkv.bias", [3072]], ["blocks.9.attn.proj.weight", [1024, 1024]], ["blocks.9.attn.proj.bias", [1024]], ["blocks.9.norm2.weight", [1024]], ["blocks.9.norm2.bias", [1024]], ["blocks.9.mlp.fc1.weight", [4096, 1024]], ["blocks.9.mlp.fc1.bias", [4096]], ["blocks.9.mlp.fc2.weight", [1024, 4096]], ["blocks.9.mlp.fc2.bias", [1024]], ["blocks.10.norm1.weight", [1024]], ["blocks.10.norm1.bias", [1024]], ["blocks.10.attn.qkv.weight", [3072, 1024]], ["blocks.10.attn.qkv.bias", [3072]], ["blocks.10.attn.proj.weight", [1024, 1024]], ["blocks.10.attn.proj.bias", [1024]], ["blocks.10.norm2.weight", [1024]], ["blocks.10.norm2.bias", [1024]], ["blocks.10.mlp.fc1.weight", [4096, 1024]], ["blocks.10.mlp.fc1.bias", [4096]], ["blocks.10.mlp.fc2.weight", [1024, 4096]], ["blocks.10.mlp.fc2.bias", [1024]], ["blocks.11.norm1.weight", [1024]], ["blocks.11.norm1.bias", [1024]], ["blocks.11.attn.qkv.weight", [3072, 1024]], ["blocks.11.attn.qkv.bias", [3072]], ["blocks.11.attn.proj.weight", [1024, 1024]], ["blocks.11.attn.proj.bias", [1024]], ["blocks.11.norm2.weight", [1024]], ["blocks.11.norm2.bias", [1024]], ["blocks.11.mlp.fc1.weight", [4096, 1024]], ["blocks.11.mlp.fc1.bias", [4096]], ["blocks.11.mlp.fc2.weight", [1024, 4096]], ["blocks.11.mlp.fc2.bias", [1024]], ["blocks.12.norm1.weight", [1024]], ["blocks.12.norm1.bias", [1024]], ["blocks.12.attn.qkv.weight", [3072, 1024]], ["blocks.12.attn.qkv.bias", [3072]], ["blocks.12.attn.proj.weight", [1024, 1024]], ["blocks.12.attn.proj.bias", [1024]], ["blocks.12.norm2.weight", [1024]], ["blocks.12.norm2.bias", [1024]], ["blocks.12.mlp.fc1.weight", [4096, 1024]], ["blocks.12.mlp.fc1.bias", [4096]], ["blocks.12.mlp.fc2.weight", [1024, 4096]], ["blocks.12.mlp.fc2.bias", [1024]], ["blocks.13.norm1.weight", [1024]], ["blocks.13.norm1.bias", [1024]], ["blocks.13.attn.qkv.weight", [3072, 1024]], ["blocks.13.attn.qkv.bias", [3072]], ["blocks.13.attn.proj.weight", [1024, 1024]], ["blocks.13.attn.proj.bias", [1024]], ["blocks.13.norm2.weight", [1024]], ["blocks.13.norm2.bias", [1024]], ["blocks.13.mlp.fc1.weight", [4096, 1024]], ["blocks.13.mlp.fc1.bias", [4096]], ["blocks.13.mlp.fc2.weight", [1024, 4096]], ["blocks.13.mlp.fc2.bias", [1024]], ["blocks.14.norm1.weight", [1024]], ["blocks.14.norm1.bias", [1024]], ["blocks.14.attn.qkv.weight", [3072, 1024]], ["blocks.14.attn.qkv.bias", [3072]], ["blocks.14.attn.proj.weight", [1024, 1024]], ["blocks.14.attn.proj.bias", [1024]], ["blocks.14.norm2.weight", [1024]], ["blocks.14.norm2.bias", [1024]], ["blocks.14.mlp.fc1.weight", [4096, 1024]], ["blocks.14.mlp.fc1.bias", [4096]], ["blocks.14.mlp.fc2.weight", [1024, 4096]], ["blocks.14.mlp.fc2.bias", [1024]], ["blocks.15.norm1.weight", [1024]], ["blocks.15.norm1.bias", [1024]], ["blocks.15.attn.qkv.weight", [3072, 1024]], ["blocks.15.attn.qkv.bias", [3072]], ["blocks.15.attn.proj.weight", [1024, 1024]], ["blocks.15.attn.proj.bias", [1024]], ["blocks.15.norm2.weight", [1024]], ["blocks.15.norm2.bias", [1024]], ["blocks.15.mlp.fc1.weight", [4096, 1024]], ["blocks.15.mlp.fc1.bias", [4096]], ["blocks.15.mlp.fc2.weight", [1024, 4096]], ["blocks.15.mlp.fc2.bias", [1024]], ["blocks.16.norm1.weight", [1024]], ["blocks.16.norm1.bias", [1024]], ["blocks.16.attn.qkv.weight", [3072, 1024]], ["blocks.16.attn.qkv.bias", [3072]], ["blocks.16.attn.proj.weight", [1024, 1024]], ["blocks.16.attn.proj.bias", [1024]], ["blocks.16.norm2.weight", [1024]], ["blocks.16.norm2.bias", [1024]], ["blocks.16.mlp.fc1.weight", [4096, 1024]], ["blocks.16.mlp.fc1.bias", [4096]], ["blocks.16.mlp.fc2.weight", [1024, 4096]], ["blocks.16.mlp.fc2.bias", [1024]], ["blocks.17.norm1.weight", [1024]], ["blocks.17.norm1.bias", [1024]], ["blocks.17.attn.qkv.weight", [3072, 1024]], ["blocks.17.attn.qkv.bias", [3072]], ["blocks.17.attn.proj.weight", [1024, 1024]], ["blocks.17.attn.proj.bias", [1024]], ["blocks.17.norm2.weight", [1024]], ["blocks.17.norm2.bias", [1024]], ["blocks.17.mlp.fc1.weight", [4096, 1024]], ["blocks.17.mlp.fc1.bias", [4096]], ["blocks.17.mlp.fc2.weight", [1024, 4096]], ["blocks.17.mlp.fc2.bias", [1024]], ["blocks.18.norm1.weight", [1024]], ["blocks.18.norm1.bias", [1024]], ["blocks.18.attn.qkv.weight", [3072, 1024]], ["blocks.18.attn.qkv.bias", [3072]], ["blocks.18.attn.proj.weight", [1024, 1024]], ["blocks.18.attn.proj.bias", [1024]], ["blocks.18.norm2.weight", [1024]], ["blocks.18.norm2.bias", [1024]], ["blocks.18.mlp.fc1.weight", [4096, 1024]], ["blocks.18.mlp.fc1.bias", [4096]], ["blocks.18.mlp.fc2.weight", [1024, 4096]], ["blocks.18.mlp.fc2.bias", [1024]], ["blocks.19.norm1.weight", [1024]], ["blocks.19.norm1.bias", [1024]], ["blocks.19.attn.qkv.weight", [3072, 1024]], ["blocks.19.attn.qkv.bias", [3072]], ["blocks.19.attn.proj.weight", [1024, 1024]], ["blocks.19.attn.proj.bias", [1024]], ["blocks.19.norm2.weight", [1024]], ["blocks.19.norm2.bias", [1024]], ["blocks.19.mlp.fc1.weight", [4096, 1024]], ["blocks.19.mlp.fc1.bias", [4096]], ["blocks.19.mlp.fc2.weight", [1024, 4096]], ["blocks.19.mlp.fc2.bias", [1024]], ["blocks.20.norm1.weight", [1024]], ["blocks.20.norm1.bias", [1024]], ["blocks.20.attn.qkv.weight", [3072, 1024]], ["blocks.20.attn.qkv.bias", [3072]], ["blocks.20.attn.proj.weight", [1024, 1024]], ["blocks.20.attn.proj.bias", [1024]], ["blocks.20.norm2.weight", [1024]], ["blocks.20.norm2.bias", [1024]], ["blocks.20.mlp.fc1.weight", [4096, 1024]], ["blocks.20.mlp.fc1.bias", [4096]], ["blocks.20.mlp.fc2.weight", [1024, 4096]], ["blocks.20.mlp.fc2.bias", [1024]], ["blocks.21.norm1.weight", [1024]], ["blocks.21.norm1.bias", [1024]], ["blocks.21.attn.qkv.weight", [3072, 1024]], ["blocks.21.attn.qkv.bias", [3072]], ["blocks.21.attn.proj.weight", [1024, 1024]], ["blocks.21.attn.proj.bias", [1024]], ["blocks.21.norm2.weight", [1024]], ["blocks.21.norm2.bias", [1024]], ["blocks.21.mlp.fc1.weight", [4096, 1024]], ["blocks.21.mlp.fc1.bias", [4096]], ["blocks.21.mlp.fc2.weight", [1024, 4096]], ["blocks.21.mlp.fc2.bias", [1024]], ["blocks.22.norm1.weight", [1024]], ["blocks.22.norm1.bias", [1024]], ["blocks.22.attn.qkv.weight", [3072, 1024]], ["blocks.22.attn.qkv.bias", [3072]], ["blocks.22.attn.proj.weight", [1024, 1024]], ["blocks.22.attn.proj.bias", [1024]], ["blocks.22.norm2.weight", [1024]], ["blocks.22.norm2.bias", [1024]], ["blocks.22.mlp.fc1.weight", [4096, 1024]], ["blocks.22.mlp.fc1.bias", [4096]], ["blocks.22.mlp.fc2.weight", [1024, 4096]], ["blocks.22.mlp.fc2.bias", [1024]], ["blocks.23.norm1.weight", [1024]], ["blocks.23.norm1.bias", [1024]], ["blocks.23.attn.qkv.weight", [3072, 1024]], ["blocks.23.attn.qkv.bias", [3072]], ["blocks.23.attn.proj.weight", [1024, 1024]], ["blocks.23.attn.proj.bias", [1024]], ["blocks.23.norm2.weight", [1024]], ["blocks.23.norm2.bias", [1024]], ["blocks.23.mlp.fc1.weight", [4096, 1024]], ["blocks.23.mlp.fc1.bias", [4096]], ["blocks.23.mlp.fc2.weight", [1024, 4096]], ["blocks.23.mlp.fc2.bias", [1024]], ["norm.weight", [1024]], ["norm.bias", [1024]], ["head.weight", [2, 1024]], ["head.bias", [2]]], "output_shape": [[100, 1201, 1024]], "num_parameters": [1024, 307968, 768, 256, 262144, 1024, 262144, 1024, 131072, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 3145728, 3072, 1048576, 1024, 1024, 1024, 4194304, 4096, 4194304, 1024, 1024, 1024, 2048, 2]}, {"name": "decoder", "id": 139742019286496, "class_name": "DecoderDoubleUpsampling(\n  (conv_0): Conv2d(3072, 256, kernel_size=(1, 1), stride=(1, 1))\n  (conv_1): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n  (norm): LayerNorm((256, 20, 20), eps=1e-05, elementwise_affine=True)\n)", "parameters": [["conv_0.weight", [256, 3072, 1, 1]], ["conv_0.bias", [256]], ["conv_1.weight", [3, 256, 1, 1]], ["conv_1.bias", [3]], ["norm.weight", [256, 20, 20]], ["norm.bias", [256, 20, 20]]], "output_shape": [[100, 3, 160, 160]], "num_parameters": [786432, 256, 768, 3, 102400, 102400]}], "edges": []}